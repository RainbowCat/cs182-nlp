{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_evaluation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrNnnPuaq4bKS+cmWL5Ifm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab03eb5c48d04d909ecc0d2d3d5c94dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f847237215b84071b626908737e03f74","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9f71f078ac241adbab52abdb8361581","IPY_MODEL_d8ab8ec49f2a4ea983e4214a225d21ce"]}},"f847237215b84071b626908737e03f74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9f71f078ac241adbab52abdb8361581":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1a6708570ead4371a3bb69c44f36f1c6","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":16,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81bf182221b54fcea3e7f16428f15438"}},"d8ab8ec49f2a4ea983e4214a225d21ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_830f18aabb384e979ab2a811fb238989","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16/16 [09:33&lt;00:00, 35.83s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71961c80caf24d5295545e41220fb7d8"}},"1a6708570ead4371a3bb69c44f36f1c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"81bf182221b54fcea3e7f16428f15438":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"830f18aabb384e979ab2a811fb238989":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"71961c80caf24d5295545e41220fb7d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"P9u_jxYuES-1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620799015976,"user_tz":420,"elapsed":25178,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"79b7975c-bdca-4987-9527-7e5f752bbe7a"},"source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install segtok\n","\n","!pip install vaderSentiment\n","!pip install nltk\n","!pip install huggingface_hub\n","!pip install pytorch-lightning"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n","Requirement already satisfied: segtok in /usr/local/lib/python3.7/dist-packages (1.5.10)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok) (2019.12.20)\n","Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (0.0.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.0.12)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.41.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->huggingface_hub) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->huggingface_hub) (3.7.4.3)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n","Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.3.0)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.18.2)\n","Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (5.4.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n","Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2021.4.0)\n","Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.3.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (20.9)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n","Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning) (3.7.4.post0)\n","Requirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning) (2.4.7)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (56.1.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.28.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.12.4)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (1.6.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (20.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (5.1.0)\n","Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (3.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.10.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeT_xpB_zaq8","executionInfo":{"status":"ok","timestamp":1620790979723,"user_tz":420,"elapsed":24948,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"bf37763d-50e2-49d7-f610-ae6fc7c8115b"},"source":["import os\n","import sys\n","from pathlib import Path\n","\n","import json\n","import pandas as pd\n","import random\n","\n","import torch\n","from segtok import tokenizer\n","\n","import tqdm\n","\n","from multiprocessing import Pool\n","\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","import tokenize\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"V4rcuiFJzepd","executionInfo":{"status":"ok","timestamp":1620799028349,"user_tz":420,"elapsed":286,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":[""],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fl18o2BYE9qW","executionInfo":{"status":"ok","timestamp":1620799028529,"user_tz":420,"elapsed":271,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"88da8d05-55a1-4630-adba-9ca6396b8396"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nuvDLN8AEb5R","executionInfo":{"status":"ok","timestamp":1620799613835,"user_tz":420,"elapsed":381,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["from pathlib import Path\n","ROOT_FOLDER = Path(\"/content/drive/My Drive/cs182_final_project/cs182-nlp\")\n","DATA_FOLDER = ROOT_FOLDER / \"dataset\"\n","TORCH_CHECKPOINT_MODEL = ROOT_FOLDER / \"final_pt_files\" / \"training_checkpoint_oscar_vaderless_5_class.pt\"\n","sys.path.append(str(ROOT_FOLDER))"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0MVoxOhFBl8","executionInfo":{"status":"ok","timestamp":1620799613835,"user_tz":420,"elapsed":372,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["USE_VADER=False"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4h4hETyFFcX","executionInfo":{"status":"ok","timestamp":1620799029898,"user_tz":420,"elapsed":731,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["import data_loader_oscar as data"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dkFe67F0PvV","executionInfo":{"status":"ok","timestamp":1620799030166,"user_tz":420,"elapsed":726,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["class LanguageModel(nn.Module):\n","    def __init__(self, vocab_size, rnn_size, vader_size, num_layers=1, dropout=0, use_vader=USE_VADER):\n","        super().__init__()\n","        #################\n","        #    INPUT 1    #\n","        #################\n","        # Create an embedding layer, with 768 hidden layers\n","        self.xlnet = torch.hub.load('huggingface/pytorch-transformers', 'model', 'xlnet-base-cased')\n","        for param in self.xlnet.layer.parameters():\n","          param.requires_grad = False\n","        # Output: (vocab_size x 768), where 768 hidden layers of XLNet\n","\n","        # Coming in: torch.Size([BATCH_SIZE, vocab_size, 768])\n","        #   (XLNet has 768 hidden layers, https://huggingface.co/transformers/pretrained_models.html)\n","        conv2d_c_in = 1\n","        conv2d_c_out = 1\n","        conv2d_kernel_W = 5 # along Embedding Length\n","        conv2d_kernel_H = 5 # along Word Length\n","\n","        self.conv2D_layer = nn.Conv2d(conv2d_c_in, conv2d_c_out, (conv2d_kernel_H, conv2d_kernel_W))\n","        # Filter of (conv2d_kernel_H, conv2d_kernel_W), Cin = 1, Cout = 1\n","\n","        # Output:\n","        conv2d_out_Hout = vocab_size - ((conv2d_kernel_H - 1) // 2) * 2 # Vocab Size\n","        conv2d_out_Wout = 768 - ((conv2d_kernel_W - 1) // 2) * 2        # length\n","\n","        self.max_pool_2d = nn.MaxPool2d((conv2d_out_Hout, 1))\n","        max_pool_2d_out_height = conv2d_out_Hout // conv2d_out_Hout\n","        max_pool_2d_out_length = conv2d_out_Wout // 1\n","        #################\n","        #  INPUT 1 END  #\n","        #################\n","        \n","        #################\n","        #    INPUT 2    #\n","        #################\n","        self.lstm = None\n","        if use_vader:\n","          self.lstm = nn.LSTM(input_size=1, hidden_size=1, num_layers=num_layers, batch_first=True, dropout=dropout)\n","        else:\n","          vader_size = 0\n","        #################\n","        #  INPUT 2 END  #\n","        #################\n","\n","        self.dropout = nn.Dropout(dropout)\n","        # print(max_pool_2d_out_length + vader_size)\n","\n","        hidden_layer_dense = 100\n","\n","        self.dense = nn.Sequential(\n","                nn.Linear(max_pool_2d_out_length + vader_size, hidden_layer_dense),\n","                nn.ReLU()\n","            )\n","        self.output = nn.Linear(hidden_layer_dense, 6) # classify yelp_reviews into 5 ratings\n","    \n","    xlnet_timing = 0\n","    def forward_input_vectorized(self, x):\n","      start_time = time.time()\n","      xlnet_out = self.xlnet(x)\n","      end_time = time.time()\n","\n","      self.xlnet_timing += end_time - start_time\n","\n","      xlnet_out_hidden = xlnet_out.last_hidden_state\n","      batches_len, word_len, embedding_len = xlnet_out_hidden.shape\n","      xlnet_out_hidden = xlnet_out_hidden.reshape(batches_len, 1, word_len, embedding_len)\n","      conv2d_out = self.conv2D_layer(xlnet_out_hidden)\n","      result = self.max_pool_2d(conv2d_out)\n","      # print(result.shape)\n","      result = result.squeeze(1).squeeze(1)\n","      return result\n","\n","    def forward_input_vader(self, x):\n","      batch_size, vader_len = x.shape\n","      # print(x.reshape(batch_size, vader_len, 1).shape)\n","      output, _ = self.lstm(x.reshape(batch_size, vader_len, 1))\n","      # print(output.shape)\n","      output = output.squeeze(2)\n","      return output\n","\n","    def predict(self, vectorized_words, vadar_sentiments):\n","        logits = self.forward(vectorized_words, vadar_sentiments)\n","        prediction = logits.argmax(dim=1, keepdim=False)\n","        return prediction\n","\n","    total_time_concat = 0\n","    def forward(self, vectorized_words, vader):\n","        input1 = self.forward_input_vectorized(vectorized_words)\n","\n","        if False and self.lstm:\n","          input2 = self.forward_input_vader(vader)\n","          combined_input = (input1, input2)\n","        else:\n","          input2 = torch.zeros(input1.size()[0], 40)\n","          combined_input = (input1, input2) # Tuples need the stray comma\n","\n","        # print(input1.size(), input2.size())\n","\n","        start_time = time.time()\n","        combined_input = torch.cat(combined_input, dim=1)\n","        end_time = time.time()\n","\n","        self.total_time_concat += end_time - start_time\n","\n","        lstm_drop = self.dropout(combined_input)\n","        logits = self.dense(lstm_drop)\n","        logits = self.output(logits)\n","        return logits\n","    \n","    def loss_fn(self, prediction, target):\n","      loss_criterion = nn.CrossEntropyLoss(reduction='none')\n","      return torch.mean(loss_criterion(prediction, target - 1))"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTosDs4Rgded","executionInfo":{"status":"ok","timestamp":1620799030311,"user_tz":420,"elapsed":511,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["#TALLERCNN\n","class LanguageModelTallerCNN(nn.Module):\n","    def __init__(self, vocab_size, rnn_size, vader_size, num_layers=1, dropout=0, use_vader=USE_VADER):\n","        super().__init__()\n","        \n","        #################\n","        #    INPUT 1    #\n","        #################\n","        # Create an embedding layer, with 768 hidden layers\n","        self.xlnet = torch.hub.load('huggingface/pytorch-transformers', 'model', 'xlnet-base-cased')\n","        for param in self.xlnet.layer.parameters():\n","          param.requires_grad = False\n","        # Output: (vocab_size x 768), where 768 hidden layers of XLNet\n","\n","        # Coming in: torch.Size([BATCH_SIZE, vocab_size, 768])\n","        #   (XLNet has 768 hidden layers, https://huggingface.co/transformers/pretrained_models.html)\n","        conv2d_c_in = 1\n","        conv2d_c_out = 100\n","        conv2d_kernel_H = 768 # along Embedding Length\n","        conv2d_kernel_W = 5 # along Word Length\n","\n","        self.conv2D_layer = nn.Conv2d(conv2d_c_in, conv2d_c_out, (conv2d_kernel_W, conv2d_kernel_H))\n","        # Filter of (conv2d_kernel_W, conv2d_kernel_H), Cin = 1, Cout = 1\n","\n","        # conv2d_out torch.Size([32, 100, 124, 1])\n","\n","        # Output:\n","        conv2d_out_Wout = 1 + (vocab_size - conv2d_kernel_W) # Vocab Size\n","        conv2d_out_Hout = 1 + (768 - conv2d_kernel_H)       # length\n","\n","        self.max_pool_2d = nn.MaxPool2d((conv2d_out_Wout, 1))\n","        max_pool_2d_out_length = conv2d_out_Wout // conv2d_out_Wout\n","        max_pool_2d_out_height = conv2d_out_Hout // 1\n","        #################\n","        #  INPUT 1 END  #\n","        #################\n","        \n","        #################\n","        #    INPUT 2    #\n","        #################\n","        self.lstm = None\n","        if use_vader:\n","          self.lstm = nn.LSTM(input_size=1, hidden_size=1, num_layers=num_layers, batch_first=True, dropout=dropout)\n","        else:\n","          vader_size = 0\n","        #################\n","        #  INPUT 2 END  #\n","        #################\n","\n","        self.dropout = nn.Dropout(dropout)\n","        # print(max_pool_2d_out_height, max_pool_2d_out_length, vader_size)\n","\n","        hidden_layer_dense = 100\n","\n","        self.dense = nn.Sequential(\n","                nn.Linear(100 + vader_size, hidden_layer_dense),\n","                nn.ReLU()\n","            )\n","        self.output = nn.Linear(hidden_layer_dense, 5) # classify yelp_reviews into 5 ratings\n","    \n","    def forward_input_vectorized(self, x):\n","      xlnet_out = self.xlnet(x)\n","      xlnet_out_hidden = xlnet_out.last_hidden_state\n","      batches_len, word_len, embedding_len = xlnet_out_hidden.shape\n","      xlnet_out_hidden = xlnet_out_hidden.reshape(batches_len, 1, word_len, embedding_len)\n","      conv2d_out = self.conv2D_layer(xlnet_out_hidden)\n","      result = self.max_pool_2d(conv2d_out)\n","      result = result.squeeze(2).squeeze(2)\n","      return result\n","\n","    def forward_input_vader(self, x):\n","      batch_size, vader_len = x.shape\n","      # print(x.reshape(batch_size, vader_len, 1).shape)\n","      output, _ = self.lstm(x.reshape(batch_size, vader_len, 1))\n","      # print(output.shape)\n","      output = output.squeeze(2)\n","      return output\n","\n","    def forward(self, vectorized_words, vader):\n","        input1 = self.forward_input_vectorized(vectorized_words)\n","\n","        if self.lstm:\n","          input2 = self.forward_input_vader(vader)\n","          combined_input = (input1, input2)\n","        else:\n","          combined_input = (input1,) # Tuples need the stray comma\n","\n","        # print(input1.size(), input2.size())\n","\n","        combined_input = torch.cat(combined_input, dim=1)\n","\n","        lstm_drop = self.dropout(combined_input)\n","        logits = self.dense(lstm_drop)\n","        logits = self.output(logits)\n","        return logits\n","\n","    def predict(self, vectorized_words, vadar_sentiments):\n","        logits = self.forward(vectorized_words, vadar_sentiments)\n","        prediction = logits.argmax(dim=1, keepdim=False)\n","        return prediction+1\n","    \n","    def loss_fn(self, prediction, target):\n","      loss_criterion = nn.CrossEntropyLoss(reduction='none')\n","      return torch.mean(loss_criterion(prediction, target - 1))"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"qG5V2dp2CGk_","executionInfo":{"status":"error","timestamp":1620799030667,"user_tz":420,"elapsed":533,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"c02c8e53-194d-41d7-8c55-3894835e310a"},"source":["\n","MAX_LEN = 128\n","MAX_LEN_VADER = 40\n","BATCH_SIZE = 64\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_params = torch.load(\n","    TORCH_CHECKPOINT_MODEL, map_location=device\n",")\n","\n","list_to_device = lambda th_obj: [tensor.to(device) for tensor in th_obj]\n","\n","model = LanguageModelTallerCNN(MAX_LEN, 256, MAX_LEN_VADER)\n","# vocab_size, rnn_size, vader_size, num_layers=1, dropout=0, use_vader=True)\n","\n","model.load_state_dict(model_params[\"model_state_dict\"])\n","model = model.to(device)\n","model.eval()\n","\n","analyzer = SentimentIntensityAnalyzer()\n","xlnet_tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'xlnet-base-cased')\n","\n","def predict_stars(texts):\n","    \"\"\"\n","    text - a SINGLE texts\n","    \"\"\"\n","    # This is where you call your model to get the number of stars output\n","    vectorized_list = []\n","    vadar_sentiments_list = []\n","    for text in texts:\n","      encodings = xlnet_tokenizer.encode_plus(\n","          text,\n","          add_special_tokens=True,\n","          max_length=MAX_LEN,\n","          return_token_type_ids=False,\n","          return_attention_mask=False,\n","          truncation=True,\n","          pad_to_max_length=False,\n","      )\n","      text_encoding = encodings.get(\"input_ids\", [])\n","      vectorized, _ = data.pad_sequence(text_encoding, 0, MAX_LEN)\n","      vectorized_list.append(vectorized)\n","\n","      sentence_list = nltk.tokenize.sent_tokenize(\n","          text\n","      )  # Text is one at a time anyway here\n","      review_sentiment_sentence = []\n","      for sentence in sentence_list:\n","          vs = analyzer.polarity_scores(sentence)\n","          review_sentiment_sentence.append(vs[\"compound\"])\n","      vadar_sentiments, _ = data.pad_sequence(review_sentiment_sentence, 0, MAX_LEN_VADER)\n","      vadar_sentiments_list.append(vadar_sentiments)\n","\n","    # Place the data as a batch, even if there is only 1\n","    vectorized = data.batch_to_torch_long(vectorized_list)\n","    vadar_sentiments = data.batch_to_torch_float(vadar_sentiments_list)\n","\n","    p = model.predict(vectorized, vadar_sentiments)\n","    return p.tolist()\n"],"execution_count":68,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-67d59ef2ffc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model_params = torch.load(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mTORCH_CHECKPOINT_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/cs182_final_project/cs182-nlp/final_pt_files/training_checkpoint_oscar_vaderless_5_class.pt.pt'"]}]},{"cell_type":"code","metadata":{"id":"gwJWTwMr4_CF","executionInfo":{"status":"ok","timestamp":1620799030796,"user_tz":420,"elapsed":420,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["from argparse import Namespace\n","\n","args = Namespace(\n","    batch_size=32,\n","    epochs=10,\n","    max_len=128,\n","    max_len_vader=40,\n","    use_bert=False,\n","    use_cnn=True,\n","    use_vader=True,\n",")"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"H45VoswUoyT-","executionInfo":{"status":"ok","timestamp":1620799030969,"user_tz":420,"elapsed":362,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["def load_json(file_path, filter_function=lambda x: True):\n","  \"\"\"\n","  file_path - full path of the file to read from\n","  filter_function - a data selection function, returns True to ADD a data point\n","  \"\"\"\n","  result = []\n","\n","  try:\n","    with open(file_path, \"r\") as f:\n","      for line in f:\n","        json_line = json.loads(line)\n","        if not filter_function(json_line):\n","          # Disallow via opposite of allow\n","          continue\n","        result.append(json_line) # each line is one data point dictionary\n","    return pd.DataFrame.from_records(result)\n","    # return result\n","\n","  except IOError:\n","    print(f\"cannot open {file_path}\")\n","    return None"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"klLrRZdWpNmp","executionInfo":{"status":"ok","timestamp":1620799031766,"user_tz":420,"elapsed":545,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["analyzer = SentimentIntensityAnalyzer()\n","\n","def format_reviews(tokenizer, datatable, indices=None, task_bar=False, review_sentiment_dict=None):\n","  encoded_reviews = []\n","  encoded_reviews_mask = []\n","  review_sentiment = []\n","  reviews_to_process = datatable[[\"review_id\", \"text\", \"stars\"]]\n","  # display(reviews_to_process)\n","  if indices is not None:\n","    reviews_to_process = reviews_to_process.iloc[indices]\n","  \n","  review_iterator = reviews_to_process.iterrows()\n","  if task_bar:\n","    review_iterator = tqdm.notebook.tqdm(reviews_to_process.iterrows(), total=reviews_to_process.shape[0])\n","\n","  for i, review in review_iterator:\n","    # Tokenize by TOKENIZER\n","    review_text = review[\"text\"]\n","    numerized = tokenize_review(tokenizer, review_text)\n","    padded, mask = pad_sequence(numerized, 0, MAX_LEN)\n","    encoded_reviews.append(padded)\n","    encoded_reviews_mask.append(mask)\n","    # VADER\n","    if review_sentiment_dict is None:\n","      sentence_list = nltk.tokenize.sent_tokenize(review_text)\n","      review_sentiment_sentence = []\n","      for sentence in sentence_list:\n","          vs = analyzer.polarity_scores(sentence)\n","          review_sentiment_sentence.append(vs[\"compound\"])\n","      padded, _ = pad_sequence(review_sentiment_sentence, 0, MAX_LEN_VADER)\n","      review_sentiment.append(padded)\n","    else:\n","      if review[\"review_id\"] in review_sentiment_dict:\n","        review_sentiment.append(review_sentiment_dict[review[\"review_id\"]])\n","    \n","  torch_encoded_reviews, torch_encoded_reviews_target = \\\n","                    batch_to_torch_long(encoded_reviews, reviews_to_process[\"stars\"].values)\n","  torch_encoded_reviews_mask, torch_review_sentiment = batch_to_torch_float(encoded_reviews_mask, review_sentiment)\n","  return torch_encoded_reviews, torch_encoded_reviews_target, torch_review_sentiment, torch_encoded_reviews_mask"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"56EqFFcrpY7v","executionInfo":{"status":"ok","timestamp":1620799031933,"user_tz":420,"elapsed":206,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["def batch_to_torch_long(*batches):\n","  if len(batches) == 1:\n","    return torch.LongTensor(batches[0])\n","  return [torch.LongTensor(batch) for batch in batches]\n","\n","def batch_to_torch_float(*batches):\n","  if len(batches) == 1:\n","    return torch.FloatTensor(batches[0])\n","  return [torch.FloatTensor(batch) for batch in batches]"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKv7bNLEpbsR","executionInfo":{"status":"ok","timestamp":1620799032511,"user_tz":420,"elapsed":274,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["def pad_sequence(numerized, pad_index, to_length, beginning=True):\n","    pad = numerized[:to_length]\n","    if beginning:\n","      padded = [pad_index] * (to_length - len(pad)) + pad\n","    else:\n","      padded = pad + [pad_index] * (to_length - len(pad))\n","    mask = [w != pad_index for w in padded]\n","    return padded, mask"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8yh6gE0pfzH","executionInfo":{"status":"ok","timestamp":1620799032836,"user_tz":420,"elapsed":250,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["def tokenize_review(tokenizer, review_text):\n","  encodings = tokenizer.encode_plus(review_text, add_special_tokens=True,\n","                                    max_length=MAX_LEN,\n","                                    return_token_type_ids=False,\n","                                    return_attention_mask=False,\n","                                    truncation=True,\n","                                    pad_to_max_length=False)\n","  return encodings.get(\"input_ids\", [])"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZT4YgPnqCeE-","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ab03eb5c48d04d909ecc0d2d3d5c94dc","f847237215b84071b626908737e03f74","e9f71f078ac241adbab52abdb8361581","d8ab8ec49f2a4ea983e4214a225d21ce","1a6708570ead4371a3bb69c44f36f1c6","81bf182221b54fcea3e7f16428f15438","830f18aabb384e979ab2a811fb238989","71961c80caf24d5295545e41220fb7d8"]},"executionInfo":{"status":"ok","timestamp":1620799613425,"user_tz":420,"elapsed":580519,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"26ab8013-fe4f-4983-9558-41d66a16a665"},"source":["count = 0\n","total_time = 0\n","\n","model.eval()\n","\n","model.total_time_concat = 0\n","model.xlnet_timing = 0\n","predictions=[]\n","\n","\n","\n","if len(sys.argv) > 1:\n","    validation_file = str(DATA_FOLDER / \"yelp_review_training_dataset.jsonl\")\n","    with open(\"output.jsonl\", \"w\") as fw:\n","        pandas_dataset = data.load_json(validation_file)\n","        pandas_dataset = pandas_dataset[:1000]\n","        full_table = pandas_dataset.copy(deep=True)\n","        dataset_batch_cap = ( pandas_dataset.shape[0] // BATCH_SIZE ) + (1 if pandas_dataset.shape[0] % BATCH_SIZE > 0 else 0)\n","        \n","        t = tqdm.notebook.tqdm(range(0, dataset_batch_cap), initial = 0, total = dataset_batch_cap)\n","        \n","        for i in t:\n","          val_start_i = i*BATCH_SIZE\n","          val_end_i = (i+1)*BATCH_SIZE\n","          # print(val_start_i, val_end_i, indices.shape)\n","\n","          data_subset = pandas_dataset.iloc[val_start_i:val_end_i]\n","          \n","          # batch\n","          batch_val = data.format_reviews(args, datatable=data_subset)\n","\n","          \"\"\"\n","          return (\n","              torch.LongTensor(encoded_reviews),  # text\n","              torch.FloatTensor(review_sentiments),  # sentiments\n","              torch.LongTensor(reviews_to_process[\"stars\"].values),  # target\n","              torch.FloatTensor(encoded_reviews_mask),  # mask\n","          )\n","          \"\"\"\n","          start_time = time.time()\n","          (batch_input_val, batch_review_sentiment_val, batch_target_val, batch_target_mask_val) = batch_val\n","          # print(batch_input_val.shape, batch_review_sentiment_val.shape)\n","          (batch_input_val, batch_target_val) = list_to_device((batch_input_val, batch_target_val))\n","          batch_target_mask_val, batch_review_sentiment_val = list_to_device((batch_target_mask_val, batch_review_sentiment_val))\n","          end_time = time.time()\n","          print(\"process time\", end_time - start_time)\n","\n","          # forward pass\n","          start_time = time.time()\n","          prediction = model.predict(batch_input_val, batch_review_sentiment_val)\n","          end_time = time.time()\n","          total_time += end_time - start_time\n","\n","          # print(prediction)\n","          for i, pred_val in enumerate(prediction):\n","            pred_val = pred_val.item()\n","            count += 1\n","            fw.write(\n","                json.dumps(\n","                    {\n","                        \"review_id\": data_subset.iloc[i][\"review_id\"],\n","                        \"predicted_stars\": float(pred_val),\n","                    }\n","                )\n","                + \"\\n\"\n","            )\n","\n","            predictions.append(float(pred_val))\n","          print(count, total_time, model.total_time_concat, total_time - model.total_time_concat)\n","          print(\"xlnet_timing\", model.xlnet_timing)\n","    full_table['pred'] = predictions\n","    print(full_table[['text', 'stars', 'pred']])\n","    print(\"Output prediction file written\")\n","else:\n","    print(\"No validation file given\")"],"execution_count":75,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab03eb5c48d04d909ecc0d2d3d5c94dc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","64it [00:00, 333.31it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 0.0028460025787353516\n","64 45.892333030700684 0 45.892333030700684\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 401.24it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 0.0009753704071044922\n","128 80.2061882019043 0 80.2061882019043\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 364.42it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 7.62939453125e-05\n","192 114.21851968765259 0 114.21851968765259\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 349.38it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 0.0001232624053955078\n","256 148.3859829902649 0 148.3859829902649\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 342.20it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 0.00041031837463378906\n","320 182.45798206329346 0 182.45798206329346\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 416.84it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 6.67572021484375e-05\n","384 216.4841468334198 0 216.4841468334198\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 409.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 6.29425048828125e-05\n","448 250.27756929397583 0 250.27756929397583\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 422.44it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 6.628036499023438e-05\n","512 284.1543462276459 0 284.1543462276459\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 447.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 7.557868957519531e-05\n","576 318.14527583122253 0 318.14527583122253\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 364.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 0.0011687278747558594\n","640 351.994845867157 0 351.994845867157\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 354.62it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 6.246566772460938e-05\n","704 385.98654294013977 0 385.98654294013977\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 368.76it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 6.413459777832031e-05\n","768 420.04657649993896 0 420.04657649993896\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 318.86it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 9.489059448242188e-05\n","832 454.0319514274597 0 454.0319514274597\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 386.85it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 5.817413330078125e-05\n","896 487.915935754776 0 487.915935754776\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","64it [00:00, 491.31it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 6.604194641113281e-05\n","960 521.9944207668304 0 521.9944207668304\n","xlnet_timing 0\n"],"name":"stdout"},{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n","40it [00:00, 382.62it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["process time 5.5789947509765625e-05\n","1000 546.2827398777008 0 546.2827398777008\n","xlnet_timing 0\n","\n","                                                  text  stars  pred\n","0    Total bill for this horrible service? Over $8G...    1.0   1.0\n","1    I *adore* Travis at the Hard Rock's new Kelly ...    5.0   5.0\n","2    I have to say that this office really has it t...    5.0   5.0\n","3    Went in for a lunch. Steak sandwich was delici...    5.0   4.0\n","4    Today was my second out of three sessions I ha...    1.0   1.0\n","..                                                 ...    ...   ...\n","995  Amazing ice cream parlour!!!! We were staying ...    5.0   5.0\n","996  If you enjoy luxuries like electricity and run...    1.0   1.0\n","997  Since hiring a new gm this place has been wort...    5.0   3.0\n","998  We are two of many many regulars at Rainbow do...    5.0   3.0\n","999  I went to Chirofit after a car accident, and i...    5.0   4.0\n","\n","[1000 rows x 3 columns]\n","Output prediction file written\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1LaEHgLGA2U2","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1620799613427,"user_tz":420,"elapsed":579654,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"c9beb509-ea2a-4f74-bd3c-234dd1fdb366"},"source":["full_table"],"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>text</th>\n","      <th>stars</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n","      <td>Total bill for this horrible service? Over $8G...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n","      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n","      <td>I have to say that this office really has it t...</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n","      <td>Went in for a lunch. Steak sandwich was delici...</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n","      <td>Today was my second out of three sessions I ha...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>TeiAGn3qkhsYgyv0S55tPA</td>\n","      <td>Amazing ice cream parlour!!!! We were staying ...</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>yUTYW80FshETGWvEiln4UA</td>\n","      <td>If you enjoy luxuries like electricity and run...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>AlLMzLafPOGkc1cq_segEA</td>\n","      <td>Since hiring a new gm this place has been wort...</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>33-nBp679e10xwvevM5hKA</td>\n","      <td>We are two of many many regulars at Rainbow do...</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>S48o5JkdHaDAIFPgz9kVdg</td>\n","      <td>I went to Chirofit after a car accident, and i...</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["                  review_id  ... pred\n","0    Q1sbwvVQXV2734tPgoKj4Q  ...  1.0\n","1    GJXCdrto3ASJOqKeVWPi6Q  ...  5.0\n","2    2TzJjDVDEuAW6MR5Vuc1ug  ...  5.0\n","3    yi0R0Ugj_xUx_Nek0-_Qig  ...  4.0\n","4    11a8sVPMUFtaC7_ABRkmtw  ...  1.0\n","..                      ...  ...  ...\n","995  TeiAGn3qkhsYgyv0S55tPA  ...  5.0\n","996  yUTYW80FshETGWvEiln4UA  ...  1.0\n","997  AlLMzLafPOGkc1cq_segEA  ...  3.0\n","998  33-nBp679e10xwvevM5hKA  ...  3.0\n","999  S48o5JkdHaDAIFPgz9kVdg  ...  4.0\n","\n","[1000 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"NKoOsugVwg9B","executionInfo":{"status":"ok","timestamp":1620799613428,"user_tz":420,"elapsed":578301,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}}},"source":["full_table['distance'] = np.abs(full_table['stars'] - full_table['pred'])"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"n88NxAVixJMa","executionInfo":{"status":"ok","timestamp":1620794105685,"user_tz":420,"elapsed":500,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"23da56d5-b7c4-40d8-f92f-419a5d877941"},"source":["full_table.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>text</th>\n","      <th>stars</th>\n","      <th>pred</th>\n","      <th>distance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n","      <td>Total bill for this horrible service? Over $8G...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n","      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n","      <td>I have to say that this office really has it t...</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n","      <td>Went in for a lunch. Steak sandwich was delici...</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n","      <td>Today was my second out of three sessions I ha...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                review_id  ... distance\n","0  Q1sbwvVQXV2734tPgoKj4Q  ...      0.0\n","1  GJXCdrto3ASJOqKeVWPi6Q  ...      0.0\n","2  2TzJjDVDEuAW6MR5Vuc1ug  ...      0.0\n","3  yi0R0Ugj_xUx_Nek0-_Qig  ...      1.0\n","4  11a8sVPMUFtaC7_ABRkmtw  ...      0.0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcGHdhPyxTpi","executionInfo":{"status":"ok","timestamp":1620794110984,"user_tz":420,"elapsed":316,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"167ce22d-53ec-4f80-a7c2-8cf3ebefaf10"},"source":["sum(full_table['distance'])/1000"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.624"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"0eMyTGKHyAEt"},"source":["\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"FZ-e5wajxZmZ","executionInfo":{"status":"ok","timestamp":1620794115977,"user_tz":420,"elapsed":672,"user":{"displayName":"Chandana Bhimarao","photoUrl":"","userId":"17089847895379828126"}},"outputId":"6c7f03a1-0ece-4223-f921-edebf0d4d07d"},"source":["# compute the confusion matrix\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","confusion_mtx = confusion_matrix(full_table['stars'], full_table['pred']) \n","# plot the confusion matrix\n","plot_confusion_matrix(confusion_mtx, classes = range(1,5))\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"9pPQAorMxsPx"},"source":[""],"execution_count":null,"outputs":[]}]}